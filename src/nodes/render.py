"""Stage 5: Render - åˆå¹¶è¾“å‡º"""

from datetime import datetime
from pathlib import Path

from ..state import TranslationState, Segment, CheckpointState
from ..config import DATA_DIR, config
from ..llm import LLMManager


def render_output(state: TranslationState) -> TranslationState:
    """åˆå¹¶æ‰€æœ‰ç¿»è¯‘æ®µè½ï¼Œç”Ÿæˆæœ€ç»ˆè¾“å‡º
    
    Stage 5 èŠ‚ç‚¹ï¼š
    - æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥æ®µè½ï¼ˆå¦‚æœ‰åˆ™æŠ¥é”™ï¼‰
    - æŒ‰é¡ºåºåˆå¹¶æ‰€æœ‰ç¿»è¯‘
    - è¾“å‡ºåˆ°è¾“å…¥æ–‡ä»¶åŒç›®å½•
    - æ·»åŠ å…ƒä¿¡æ¯
    
    Args:
        state: å½“å‰çŠ¶æ€
    
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    book_id = state["book_id"]
    book_name = state["book_name"]
    source_path = state["source_path"]
    segments_data = state["segments"]
    failed_segments = state.get("failed_segments", [])
    
    print(f"ğŸ“ åˆå¹¶è¾“å‡º...")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥æ®µè½
    if failed_segments:
        print(f"âš ï¸  å­˜åœ¨ {len(failed_segments)} ä¸ªå¤±è´¥æ®µè½: {failed_segments}")
        print(f"   å°†ç»§ç»­åˆå¹¶ï¼Œä½†è¿™äº›æ®µè½å¯èƒ½åŒ…å«æœªç¿»è¯‘å†…å®¹")
    
    try:
        book_dir = DATA_DIR / book_id
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„ï¼šè¾“å…¥æ–‡ä»¶åŒç›®å½•
        source_file = Path(source_path)
        if source_file.exists():
            output_dir = source_file.parent
            # è¾“å‡ºæ–‡ä»¶ååŸºäºè¾“å…¥æ–‡ä»¶å
            input_stem = source_file.stem  # ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
            target_lang = config.target_language
            output_filename = f"{input_stem}_{target_lang}.md"
        else:
            # å›é€€åˆ°é»˜è®¤ç›®å½•
            output_dir = book_dir / "output"
            output_dir.mkdir(exist_ok=True)
            safe_name = "".join(c for c in book_name if c.isalnum() or c in (' ', '-', '_')).strip()
            output_filename = f"{safe_name}_{config.target_language}.md"
        
        output_file = output_dir / output_filename
        
        # æŒ‰ ID æ’åº
        sorted_segments = sorted(segments_data, key=lambda x: x["id"])
        
        # åˆå¹¶ç¿»è¯‘å†…å®¹
        translations = []
        for seg_data in sorted_segments:
            translation = seg_data.get("translation", "")
            if translation:
                translations.append(translation)
        
        if not translations:
            return {**state, "error": "æ²¡æœ‰å¯åˆå¹¶çš„ç¿»è¯‘å†…å®¹"}
        
        # æ‹¼æ¥å†…å®¹
        final_content = "\n\n".join(translations)
        
        # æ·»åŠ å…ƒä¿¡æ¯
        meta_info = generate_meta_info(state)
        final_output = f"{final_content}\n\n---\n\n{meta_info}"
        
        # ä¿å­˜è¾“å‡ºæ–‡ä»¶
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(final_output)
        
        # åŒæ—¶åœ¨ data ç›®å½•ä¿å­˜ä¸€ä»½å¤‡ä»½
        backup_dir = book_dir / "output"
        backup_dir.mkdir(exist_ok=True)
        backup_file = backup_dir / output_filename
        with open(backup_file, "w", encoding="utf-8") as f:
            f.write(final_output)
        
        # æ›´æ–°æ–­ç‚¹çŠ¶æ€
        checkpoint = CheckpointState.load(book_dir)
        if checkpoint:
            checkpoint.stage = "render"
            checkpoint.save(book_dir)
        
        print(f"âœ… è¾“å‡ºå®Œæˆ:")
        print(f"   ä¸»æ–‡ä»¶: {output_file}")
        print(f"   å¤‡ä»½: {backup_file}")
        print(f"   æ€»å­—ç¬¦æ•°: {len(final_output):,}")
        
        return {
            **state,
            "final_output": str(output_file),
            "error": None
        }
        
    except Exception as e:
        print(f"âŒ åˆå¹¶å¤±è´¥: {e}")
        return {**state, "error": str(e)}


def generate_meta_info(state: TranslationState) -> str:
    """ç”Ÿæˆç¿»è¯‘å…ƒä¿¡æ¯"""
    book_name = state["book_name"]
    total_segments = state["total_segments"]
    completed = state["completed_segments"]
    failed = state["failed_segments"]
    tokens_used = LLMManager.get_usage()
    
    lines = [
        "## ç¿»è¯‘ä¿¡æ¯",
        "",
        f"- **ä¹¦å**: {book_name}",
        f"- **ç¿»è¯‘æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"- **æ®µè½**: {completed}/{total_segments} å®Œæˆ",
    ]
    
    if failed:
        lines.append(f"- **å¤±è´¥æ®µè½**: {failed}")
    
    if tokens_used:
        lines.append("")
        lines.append("### Token ä½¿ç”¨ç»Ÿè®¡")
        for model, usage in tokens_used.items():
            lines.append(f"- {model}: è¾“å…¥ {usage['input']:,} / è¾“å‡º {usage['output']:,}")
    
    lines.append("")
    lines.append("*ç”± DeepTranslator è‡ªåŠ¨ç¿»è¯‘*")
    
    return "\n".join(lines)
